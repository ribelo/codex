{"id":"codex-4hm","title":"/review fails for non-OpenAI providers due to hardcoded review_model default","description":"When using non-OpenAI providers like antigravity, /review fails with 404 because review_model defaults to gpt-5.1-codex-max which does not exist on those providers. The review uses the same provider but different model, causing the failure.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-07T16:32:02.531502279+01:00","updated_at":"2025-12-07T16:35:16.58935878+01:00","closed_at":"2025-12-07T16:35:16.58935878+01:00"}
{"id":"codex-56f","title":"Scope Gemini OAuth to providers requiring Code Assist","description":"resolve_gemini_credential always prefers stored Gemini OAuth tokens when gemini_account_count\u003e0, forcing all Gemini providers to use Code Assist endpoint and ignoring configured API keys. Public generative-language providers break after codex login --gemini. Adjust credential selection to only use OAuth for providers that explicitly require Code Assist and keep API-key providers on their configured bearer.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-06T13:19:48.565853205+01:00","updated_at":"2025-12-06T13:27:55.960118498+01:00","closed_at":"2025-12-06T13:27:55.960118498+01:00"}
{"id":"codex-5qi","title":"Antigravity provider should not require project id","description":"","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-07T11:30:15.058435632+01:00","updated_at":"2025-12-07T11:41:06.66799857+01:00","closed_at":"2025-12-07T11:41:06.66799857+01:00"}
{"id":"codex-64j","title":"Shared MCP connection manager and lazy MCP initialization","description":"Refactor MCP so connections are shared, lazily initialized per server, and no longer block session or subagent startup. Sessions and tools should treat MCP as an optional, per-server resource with explicit readiness, and the TUI should surface server status without delaying conversation flow.","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-11T00:41:05.704146041+01:00","updated_at":"2025-12-11T01:08:13.833574857+01:00","closed_at":"2025-12-11T01:08:13.833574857+01:00"}
{"id":"codex-64j.1","title":"Harden and document MCP behavior (errors, timeouts, tests)","description":"Add tests and docs for the new MCP lifecycle: per-server lazy init, shared connections, and explicit readiness. Cover success, timeout, and failure paths, including what the model sees when a server is still starting or permanently failed. Update docs/config.md (MCP section) to describe the new behavior and any user-facing status messages.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-11T00:41:16.198131799+01:00","updated_at":"2025-12-11T01:08:10.029185972+01:00","closed_at":"2025-12-11T01:08:10.029185972+01:00","dependencies":[{"issue_id":"codex-64j.1","depends_on_id":"codex-64j","type":"parent-child","created_at":"2025-12-11T00:41:16.198413878+01:00","created_by":"daemon"}]}
{"id":"codex-64j.2","title":"Optimize subagent behavior with shared MCP clients","description":"Change subagent sessions to reuse the shared McpConnectionManager instead of reinitializing MCP per subagent. Ensure subagents pay zero MCP startup cost unless they actually invoke MCP tools, and verify that authorization/env isolation is handled via per-request metadata rather than redundant connections.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-11T00:41:16.21135687+01:00","updated_at":"2025-12-11T01:08:05.48787264+01:00","closed_at":"2025-12-11T01:08:05.48787264+01:00","dependencies":[{"issue_id":"codex-64j.2","depends_on_id":"codex-64j","type":"parent-child","created_at":"2025-12-11T00:41:16.211663315+01:00","created_by":"daemon"}]}
{"id":"codex-64j.3","title":"Add explicit MCP readiness and status to tool calls and TUI","description":"Plumb MCP server status into events so that the TUI can show per-server startup state (starting/ready/failed) without blocking the session. Update MCP tool handlers to surface clean, typed errors on not-ready/failed servers, and adjust the TUI to render these as actionable messages rather than generic tool failures.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-11T00:41:16.225203698+01:00","updated_at":"2025-12-11T01:08:00.743117603+01:00","closed_at":"2025-12-11T01:08:00.743117603+01:00","dependencies":[{"issue_id":"codex-64j.3","depends_on_id":"codex-64j","type":"parent-child","created_at":"2025-12-11T00:41:16.225523038+01:00","created_by":"daemon"}]}
{"id":"codex-64j.4","title":"Make MCP initialization lazy and per-server","description":"Remove the global upfront initialize() call from Session::new. Instead, have the MCP tool handler (and any direct users) call ensure_started(server) and wait_ready(server, timeout) before a tool call. Only initialize servers that are actually requested in a session, and ensure error paths are well-defined when a server is disabled or fails to connect.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-11T00:41:16.239103688+01:00","updated_at":"2025-12-11T01:07:56.428050943+01:00","closed_at":"2025-12-11T01:07:56.428050943+01:00","dependencies":[{"issue_id":"codex-64j.4","depends_on_id":"codex-64j","type":"parent-child","created_at":"2025-12-11T00:41:16.239380357+01:00","created_by":"daemon"}]}
{"id":"codex-64j.5","title":"Refactor McpConnectionManager into a shared, process-wide manager","description":"Move MCP connection management out of individual sessions into a shared McpConnectionManager that lives for the process (or workspace). Expose APIs to get or start a client per server (by name), track per-server status (NotConfigured/Pending/Connecting/Ready/Failed), and ensure configuration (McpServerConfig, OAuth store mode) is passed in cleanly without coupling to Session internals.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-11T00:41:16.251475348+01:00","updated_at":"2025-12-11T00:57:16.308717259+01:00","closed_at":"2025-12-11T00:57:16.308717259+01:00","dependencies":[{"issue_id":"codex-64j.5","depends_on_id":"codex-64j","type":"parent-child","created_at":"2025-12-11T00:41:16.251993197+01:00","created_by":"daemon"}]}
{"id":"codex-6kk","title":"Provider-agnostic quota support for /status (Antigravity + ChatGPT)","description":"Unify how Codex fetches and displays model usage quotas across providers, starting with ChatGPT and Antigravity. Introduce a provider-agnostic quota abstraction in core, implement an Antigravity quota client that mirrors AntigravityQuota’s GetUserStatus behavior, and wire everything into the TUI’s /status command so it always reflects the current provider’s limits and credits.","status":"open","priority":2,"issue_type":"epic","created_at":"2025-12-11T00:59:44.83405989+01:00","updated_at":"2025-12-11T00:59:44.83405989+01:00"}
{"id":"codex-6kk.1","title":"Add tests and docs for provider quota integration","description":"Add integration and snapshot tests that cover /status for both ChatGPT and Antigravity providers, including cases with missing quotas, stale data, and low-credit warnings. Ensure the TUI status card snapshots remain stable and readable. Update the docs (e.g., docs/config.md and any /status-related docs) to explain how Codex derives usage/limit information per provider, what users should expect for ChatGPT vs Antigravity, and how to troubleshoot when quota data is unavailable (e.g., Antigravity language server not running).","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-11T00:59:54.344454208+01:00","updated_at":"2025-12-11T00:59:54.344454208+01:00","dependencies":[{"issue_id":"codex-6kk.1","depends_on_id":"codex-6kk","type":"parent-child","created_at":"2025-12-11T00:59:54.344812683+01:00","created_by":"daemon"}]}
{"id":"codex-6kk.2","title":"Wire provider quotas into TUI /status for ChatGPT and Antigravity","description":"Update the TUI layer so /status always uses provider-specific quotas when available. Replace the current ChatGPT-only fetch_rate_limits() logic with a call into the new provider-agnostic quota API, and add an Antigravity branch that invokes AntigravityQuotaClient behind the same abstraction. Ensure quota fetching happens in the background (via AppEvent::RateLimitSnapshotFetched) and that /status renders correctly whether quotas are fresh, missing, or stale. Verify the status card remains provider-neutral and does not hard-code ChatGPT-specific language.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-11T00:59:54.35852021+01:00","updated_at":"2025-12-11T00:59:54.35852021+01:00","dependencies":[{"issue_id":"codex-6kk.2","depends_on_id":"codex-6kk","type":"parent-child","created_at":"2025-12-11T00:59:54.358836664+01:00","created_by":"daemon"}]}
{"id":"codex-6kk.3","title":"Design provider-agnostic quota API in core","description":"Introduce a small, provider-neutral quota abstraction in codex-core (e.g., a ProviderQuotaClient trait) that can return a standard RateLimitSnapshot for the current provider. Define how this trait discovers the right implementation based on AuthMode / model_provider_id, how it should behave when quotas are unavailable (None), and how it should avoid blocking the main turn loop (async-only, with clear timeout behavior). Document the API so other providers (Anthropic, Gemini, etc.) can plug in later without touching the TUI.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-11T00:59:54.37383815+01:00","updated_at":"2025-12-11T00:59:54.37383815+01:00","dependencies":[{"issue_id":"codex-6kk.3","depends_on_id":"codex-6kk","type":"parent-child","created_at":"2025-12-11T00:59:54.374196324+01:00","created_by":"daemon"}]}
{"id":"codex-6kk.4","title":"Implement Antigravity quota client using GetUserStatus","description":"Add an AntigravityQuotaClient in codex-core that mirrors the AntigravityQuota VS Code extension: detect the local Antigravity language_server process, discover its listening port and CSRF token, and call the /exa.language_server_pb.LanguageServerService/GetUserStatus endpoint over HTTPS. Parse the server_user_status_response into a structured Rust type, then map it into Codex’s RateLimitSnapshot + CreditsSnapshot, including monthly prompt credits, available credits, and a reasonable used_percent and reset time. Ensure the client is robust to the language server not running, connection errors, and malformed responses, returning None instead of panicking.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-11T00:59:54.389404355+01:00","updated_at":"2025-12-11T00:59:54.389404355+01:00","dependencies":[{"issue_id":"codex-6kk.4","depends_on_id":"codex-6kk","type":"parent-child","created_at":"2025-12-11T00:59:54.389727001+01:00","created_by":"daemon"}]}
{"id":"codex-6kk.5","title":"Extend RateLimitSnapshot mapping for Antigravity-specific fields","description":"Define a precise mapping from Antigravity’s GetUserStatus response into Codex’s RateLimitSnapshot and CreditsSnapshot models. Decide how to represent prompt credits (monthly vs available) and per-model quotas in the existing primary/secondary windows and credits fields without breaking ChatGPT behavior. Implement this mapping in core, add unit tests that feed in realistic AntigravityQuota-like payloads, and confirm the /status card shows intuitive percentages, reset times, and credit balances for Antigravity users.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-11T00:59:54.405867483+01:00","updated_at":"2025-12-11T00:59:54.405867483+01:00","dependencies":[{"issue_id":"codex-6kk.5","depends_on_id":"codex-6kk","type":"parent-child","created_at":"2025-12-11T00:59:54.406326319+01:00","created_by":"daemon"}]}
{"id":"codex-6wa","title":"Dynamic MCP server enumeration in tool descriptions","description":"## Problem\n\nNon-OpenAI/Anthropic models (Gemini, Kimi, GLM, Grok, etc.) hallucinate MCP server names when using `read_mcp_resource`. Most commonly they invent a 'filesystem' server to read local files, resulting in errors like:\n\n```\nError: resources/read failed: unknown MCP server 'filesystem'\n```\n\nThis happens because:\n1. Models see `read_mcp_resource` tool available\n2. They want to read a file\n3. They invent server names based on training data patterns\n\n## Solution\n\nDynamically inject the list of available MCP servers into tool descriptions at runtime. This prevents the entire class of 'invented server name' hallucinations by showing models exactly what's available upfront.\n\n## Approach\n\nExtract server names from the `mcp_tools` HashMap keys (which have format `mcp__servername__toolname`) inside `build_specs()` and pass them to MCP resource tool creation functions. Update descriptions to show:\n- Available servers list\n- Explicit guidance that there's no filesystem server\n- Direction to use shell_command for local files\n\n## Files involved\n- `core/src/tools/spec.rs` - tool creation functions\n- `core/src/mcp_connection_manager.rs` - MCP_TOOL_NAME_DELIMITER constant\n\n## Success criteria\n- Tool descriptions dynamically list available MCP servers\n- Models stop hallucinating non-existent server names\n- No changes to external interfaces or ToolsConfig struct","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-12T16:05:44.227274567+01:00","updated_at":"2025-12-12T16:44:03.81796512+01:00","closed_at":"2025-12-12T16:44:03.81796512+01:00"}
{"id":"codex-6wa.1","title":"Export MCP_TOOL_NAME_DELIMITER constant","description":"## What\n\nMake `MCP_TOOL_NAME_DELIMITER` (currently `\"__\"`) accessible from `core/src/tools/spec.rs`.\n\n## Why\n\nNeed to parse server names from qualified tool names like `mcp__exa-search__web_search`.\n\n## How\n\nIn `core/src/mcp_connection_manager.rs`:\n- Change `const MCP_TOOL_NAME_DELIMITER` from private to `pub(crate) const`\n\nOr alternatively, re-export it via `core/src/lib.rs` or `core/src/mcp/mod.rs`.\n\n## Acceptance\n- `MCP_TOOL_NAME_DELIMITER` importable in `tools/spec.rs`\n- No changes to its value or behavior","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-12T16:06:06.10762724+01:00","updated_at":"2025-12-12T16:44:03.807142844+01:00","closed_at":"2025-12-12T16:44:03.807142844+01:00","dependencies":[{"issue_id":"codex-6wa.1","depends_on_id":"codex-6wa","type":"parent-child","created_at":"2025-12-12T16:06:06.107928565+01:00","created_by":"daemon"}]}
{"id":"codex-6wa.2","title":"Extract server names from mcp_tools in build_specs()","description":"## What\n\nInside `build_specs()` function in `core/src/tools/spec.rs`, extract unique MCP server names from the `mcp_tools` HashMap keys.\n\n## Why\n\nServer names are needed to dynamically populate tool descriptions.\n\n## How\n\n```rust\nuse crate::mcp_connection_manager::MCP_TOOL_NAME_DELIMITER;\nuse std::collections::BTreeSet;\n\n// Inside build_specs():\nlet mcp_server_names: Vec\u003cString\u003e = mcp_tools\n    .as_ref()\n    .map(|tools| {\n        tools.keys()\n            .filter_map(|k| {\n                // Format: mcp__servername__toolname\n                let parts: Vec\u003c\u0026str\u003e = k.split(MCP_TOOL_NAME_DELIMITER).collect();\n                parts.get(1).map(|s| s.to_string())\n            })\n            .collect::\u003cBTreeSet\u003c_\u003e\u003e()  // Dedupe and sort\n            .into_iter()\n            .collect()\n    })\n    .unwrap_or_default();\n```\n\n## Acceptance\n- `mcp_server_names: Vec\u003cString\u003e` available in `build_specs()`\n- Names are sorted and deduplicated\n- Empty vec when no MCP tools configured","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-12T16:06:14.858233758+01:00","updated_at":"2025-12-12T16:44:03.796654516+01:00","closed_at":"2025-12-12T16:44:03.796654516+01:00","dependencies":[{"issue_id":"codex-6wa.2","depends_on_id":"codex-6wa","type":"parent-child","created_at":"2025-12-12T16:06:14.858572905+01:00","created_by":"daemon"},{"issue_id":"codex-6wa.2","depends_on_id":"codex-6wa.1","type":"blocks","created_at":"2025-12-12T16:07:18.015773071+01:00","created_by":"daemon"}]}
{"id":"codex-6wa.3","title":"Update MCP resource tool creation functions to accept server names","description":"## What\n\nModify the three MCP resource tool creation functions to accept a slice of server names:\n- `create_list_mcp_resources_tool()`\n- `create_list_mcp_resource_templates_tool()`\n- `create_read_mcp_resource_tool()`\n\n## Why\n\nThese functions need server names to build dynamic descriptions.\n\n## How\n\nChange signatures from:\n```rust\nfn create_list_mcp_resources_tool() -\u003e ToolSpec\nfn create_list_mcp_resource_templates_tool() -\u003e ToolSpec\nfn create_read_mcp_resource_tool() -\u003e ToolSpec\n```\n\nTo:\n```rust\nfn create_list_mcp_resources_tool(server_names: \u0026[String]) -\u003e ToolSpec\nfn create_list_mcp_resource_templates_tool(server_names: \u0026[String]) -\u003e ToolSpec\nfn create_read_mcp_resource_tool(server_names: \u0026[String]) -\u003e ToolSpec\n```\n\nUpdate call sites in `build_specs()` to pass `\u0026mcp_server_names`.\n\n## Acceptance\n- All three functions accept server names parameter\n- Compiles without errors\n- Tests still pass (may need updates)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-12T16:06:24.09025752+01:00","updated_at":"2025-12-12T16:44:03.828011316+01:00","closed_at":"2025-12-12T16:44:03.828011316+01:00","dependencies":[{"issue_id":"codex-6wa.3","depends_on_id":"codex-6wa","type":"parent-child","created_at":"2025-12-12T16:06:24.090623428+01:00","created_by":"daemon"},{"issue_id":"codex-6wa.3","depends_on_id":"codex-6wa.2","type":"blocks","created_at":"2025-12-12T16:07:18.048152242+01:00","created_by":"daemon"}]}
{"id":"codex-6wa.4","title":"Build dynamic descriptions with server list","description":"## What\n\nUpdate the description strings in the three MCP resource tool functions to include the available server list.\n\n## Why\n\nModels need to see available servers upfront to avoid hallucinating non-existent ones.\n\n## How\n\n### For `create_read_mcp_resource_tool`:\n\n```rust\nlet description = if server_names.is_empty() {\n    \"Read a specific resource from an MCP server. No MCP servers are currently available. For local file access, use shell_command.\".to_string()\n} else {\n    format!(\n        \"Read a specific resource from an MCP server given the server name and resource URI. Available servers: {:?}. For local file access, use shell_command instead.\",\n        server_names\n    )\n};\n```\n\n### For `create_list_mcp_resources_tool`:\n\n```rust\nlet description = if server_names.is_empty() {\n    \"Lists resources provided by MCP servers. No MCP servers are currently available.\".to_string()\n} else {\n    format!(\n        \"Lists resources provided by MCP servers. Available servers: {:?}. Resources allow servers to share data that provides context to language models.\",\n        server_names\n    )\n};\n```\n\n### For `create_list_mcp_resource_templates_tool`:\n\nSimilar pattern.\n\n## Acceptance\n- Descriptions include server list when servers exist\n- Descriptions indicate 'no servers available' when empty\n- `read_mcp_resource` mentions shell_command for file access","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-12T16:06:34.650444397+01:00","updated_at":"2025-12-12T16:44:03.838111675+01:00","closed_at":"2025-12-12T16:44:03.838111675+01:00","dependencies":[{"issue_id":"codex-6wa.4","depends_on_id":"codex-6wa","type":"parent-child","created_at":"2025-12-12T16:06:34.65076033+01:00","created_by":"daemon"},{"issue_id":"codex-6wa.4","depends_on_id":"codex-6wa.3","type":"blocks","created_at":"2025-12-12T16:07:18.063719031+01:00","created_by":"daemon"}]}
{"id":"codex-6wa.5","title":"Update tests for dynamic MCP tool descriptions","description":"## What\n\nUpdate existing tests in `core/src/tools/spec.rs` that create or verify MCP resource tools.\n\n## Why\n\nTests call the tool creation functions directly and will fail after signature changes.\n\n## How\n\nFind tests that call:\n- `create_list_mcp_resources_tool()`\n- `create_list_mcp_resource_templates_tool()`  \n- `create_read_mcp_resource_tool()`\n\nUpdate them to pass a server names slice, e.g., `\u0026[]` or `\u0026[\"test-server\".to_string()]`.\n\nAlso consider adding new test cases:\n1. Empty server list produces expected description\n2. Non-empty server list includes servers in description\n\n## Acceptance\n- All existing tests pass\n- New test verifies description contains server names when provided","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-12T16:06:44.305542595+01:00","updated_at":"2025-12-12T16:06:44.305542595+01:00","dependencies":[{"issue_id":"codex-6wa.5","depends_on_id":"codex-6wa","type":"parent-child","created_at":"2025-12-12T16:06:44.30622701+01:00","created_by":"daemon"},{"issue_id":"codex-6wa.5","depends_on_id":"codex-6wa.4","type":"blocks","created_at":"2025-12-12T16:07:18.032792289+01:00","created_by":"daemon"}]}
{"id":"codex-7kf","title":"Migrate Custom Features (Providers, Subagents, UI)","description":"","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-05T13:57:24.388988989+01:00","updated_at":"2025-12-05T16:02:22.845701629+01:00","closed_at":"2025-12-05T16:02:22.845701629+01:00"}
{"id":"codex-7kf.1","title":"Migrate Multi-provider Support (Gemini, Anthropic)","description":"Port core backend support for Gemini and Anthropic from the old fork to codex-rs/core.\n\nSTEPS:\n1. Copy source files from old fork (core/src/):\n   - gemini.rs\n   - gemini_messages.rs\n   - anthropic_messages.rs\n2. Copy resource files:\n   - core/gemini-3-prompt.md\n3. Integrate into codex-rs/core:\n   - Update lib.rs to expose modules\n   - Update model_family.rs to include Gemini/Anthropic variants\n   - Update model_provider_info logic if necessary","notes":"Gemini + Anthropic scaffolds ported; proceeding to subagents","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-12-05T13:57:30.334759125+01:00","updated_at":"2025-12-05T15:33:33.919881922+01:00","closed_at":"2025-12-05T15:33:33.919885529+01:00","dependencies":[{"issue_id":"codex-7kf.1","depends_on_id":"codex-7kf","type":"parent-child","created_at":"2025-12-05T13:57:30.335098263+01:00","created_by":"daemon"}]}
{"id":"codex-7kf.1.1","title":"Port Gemini Support","description":"Port all Gemini-related code and assets.\n\nFILES TO COPY:\n- /core/src/gemini.rs\n- /core/src/gemini_messages.rs\n- /core/gemini-3-prompt.md\n\nINTEGRATION:\n- Add modules to core/src/lib.rs\n- Register Gemini as a provider in core/src/model_family.rs","notes":"Gemini provider files ported, compiling in codex-core","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-05T13:58:34.905643645+01:00","updated_at":"2025-12-05T15:24:55.559395065+01:00","closed_at":"2025-12-05T15:24:55.559399624+01:00","dependencies":[{"issue_id":"codex-7kf.1.1","depends_on_id":"codex-7kf.1","type":"parent-child","created_at":"2025-12-05T13:58:34.905983584+01:00","created_by":"daemon"}]}
{"id":"codex-7kf.1.2","title":"Port Anthropic Support","description":"Port Anthropic-related code.\n\nFILES TO COPY:\n- /core/src/anthropic_messages.rs\n\nINTEGRATION:\n- Add modules to core/src/lib.rs\n- Register Anthropic as a provider in core/src/model_family.rs (if distinct from OpenAI/Gemini path)","notes":"Anthropic messages/provider ported and compiling","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-05T13:58:43.383129271+01:00","updated_at":"2025-12-05T15:31:40.109495912+01:00","closed_at":"2025-12-05T15:31:40.109498948+01:00","dependencies":[{"issue_id":"codex-7kf.1.2","depends_on_id":"codex-7kf.1","type":"parent-child","created_at":"2025-12-05T13:58:43.383462036+01:00","created_by":"daemon"}]}
{"id":"codex-7kf.2","title":"Migrate Subagents Architecture","description":"Port the subagent orchestration logic to enable task delegation.\n\nSTEPS:\n1. Copy core/src/subagents.rs to codex-rs/core/src/\n2. Copy core/src/tools/handlers/task.rs to codex-rs/core/src/tools/handlers/\n3. Register the 'task' tool in the core tool registry\n4. Ensure the task handler hooks correctly into the event loop in codex-rs/app-server or core","notes":"Subagent scaffolding and task tool stubbed; responds unsupported pending full wiring","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-12-05T13:57:34.951409492+01:00","updated_at":"2025-12-05T15:43:43.070080627+01:00","closed_at":"2025-12-05T15:43:43.070085035+01:00","dependencies":[{"issue_id":"codex-7kf.2","depends_on_id":"codex-7kf","type":"parent-child","created_at":"2025-12-05T13:57:34.951692232+01:00","created_by":"daemon"}]}
{"id":"codex-7kf.3","title":"Update TUI for New Providers and Subagents","description":"Adapt the TUI to render non-OpenAI models and subagent activities.\n\nSTEPS:\n1. Port TUI view modes:\n   - Copy/Adapt tui/src/tui/inline.rs\n   - Copy/Adapt tui/src/tui/standard.rs\n2. Update rendering logic:\n   - Check tui/src/chatwidget.rs for provider-specific rendering adjustments\n   - Ensure subagent tool calls are displayed correctly","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-12-05T13:57:39.162584085+01:00","updated_at":"2025-12-05T16:02:19.277920853+01:00","closed_at":"2025-12-05T16:02:19.277920853+01:00","dependencies":[{"issue_id":"codex-7kf.3","depends_on_id":"codex-7kf","type":"parent-child","created_at":"2025-12-05T13:57:39.162905789+01:00","created_by":"daemon"}]}
{"id":"codex-83k","title":"Show model_provider and model in footer","description":"","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-12-07T16:13:54.687590171+01:00","updated_at":"2025-12-07T16:17:24.942337442+01:00","closed_at":"2025-12-07T16:17:24.942337442+01:00"}
{"id":"codex-8k0","title":"Drop legacy execpolicy + local providers","description":"Goal: reduce fork complexity and future upstream merge friction by removing two unused stacks.\n\nScope:\n1) Remove execpolicy-legacy:\n- Delete the codex-execpolicy-legacy crate and remove execpolicy-legacy from the workspace.\n- Remove any remaining references in docs, tests, and Cargo manifests/lockfile.\n\n2) Remove local providers:\n- Delete codex-lmstudio and codex-ollama crates and remove them from the workspace.\n- Remove OSS-provider plumbing tied to these crates (oss_provider config option, LMSTUDIO/OLLAMA provider IDs/ports/constants, ensure_oss_ready helpers).\n- Remove CLI/TUI flags and help text for choosing local providers.\n- Update docs and tests/snapshots that mention local providers.\n\nDone when:\n- Workspace builds and tests pass without these crates.\n- No code/docs mention execpolicy-legacy, lmstudio, ollama, or oss_provider.\n- CLI/TUI help output no longer offers local providers.","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-12T00:46:52.037997823+01:00","updated_at":"2025-12-12T01:08:24.078052292+01:00","closed_at":"2025-12-12T01:08:24.078052292+01:00"}
{"id":"codex-8k0.1","title":"Clean CLI/TUI + docs/tests","description":"Follow-up cleanup after dropping local providers:\n- Remove local-provider CLI/TUI flags and any related help text.\n- Update docs and example config to remove oss_provider and local provider mention.\n- Update or delete tests/snapshots referencing lmstudio or ollama.\n- Run targeted tests for affected crates.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-12T00:47:23.724088879+01:00","updated_at":"2025-12-12T01:08:19.386507206+01:00","closed_at":"2025-12-12T01:08:19.386507206+01:00","dependencies":[{"issue_id":"codex-8k0.1","depends_on_id":"codex-8k0","type":"parent-child","created_at":"2025-12-12T00:47:23.724700548+01:00","created_by":"daemon"}]}
{"id":"codex-8k0.2","title":"Remove lmstudio/ollama crates","description":"Delete local provider crates:\n- Remove lmstudio and ollama from codex-rs/Cargo.toml workspace members and workspace dependencies.\n- Delete codex-rs/lmstudio and codex-rs/ollama crate directories.\n- Remove their usage from codex-common OSS helper, codex-core model provider registry, and config parsing.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-12T00:47:23.749404256+01:00","updated_at":"2025-12-12T01:08:09.414548804+01:00","closed_at":"2025-12-12T01:08:09.414548804+01:00","dependencies":[{"issue_id":"codex-8k0.2","depends_on_id":"codex-8k0","type":"parent-child","created_at":"2025-12-12T00:47:23.74966263+01:00","created_by":"daemon"}]}
{"id":"codex-8k0.3","title":"Remove execpolicy-legacy crate","description":"Delete codex-execpolicy-legacy:\n- Remove execpolicy-legacy from codex-rs/Cargo.toml workspace members and workspace dependencies.\n- Delete codex-rs/execpolicy-legacy crate directory.\n- Remove references to the legacy matcher/binary from execpolicy README and any docs/tests.\n- Regenerate Cargo.lock and ensure no dependency edges remain.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-12T00:47:23.760783007+01:00","updated_at":"2025-12-12T01:08:13.729300306+01:00","closed_at":"2025-12-12T01:08:13.729300306+01:00","dependencies":[{"issue_id":"codex-8k0.3","depends_on_id":"codex-8k0","type":"parent-child","created_at":"2025-12-12T00:47:23.761067881+01:00","created_by":"daemon"}]}
{"id":"codex-bl3","title":"Gemini Low effort thinking_budget (512) is below Anthropic minimum (1024)","description":"When using Claude through Antigravity with Low reasoning effort (e.g., /review), the thinking_budget is set to 512 but Anthropic requires minimum 1024. This causes 400 errors.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-07T16:41:57.845756316+01:00","updated_at":"2025-12-07T16:47:59.841970442+01:00","closed_at":"2025-12-07T16:47:59.841970442+01:00"}
{"id":"codex-cs1","title":"Fix Gemini login prefers newest credential","description":"Gemini login currently keeps using the first stored credential; new logins append to auth.json but core picks index 0 so refreshed tokens are ignored unless users edit auth.json. Update persistence to promote most recent Gemini tokens to the front so runtime uses latest login.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-06T12:59:39.702700307+01:00","updated_at":"2025-12-06T13:04:15.269773177+01:00","closed_at":"2025-12-06T13:04:15.269773177+01:00"}
{"id":"codex-d55","title":"Restrict subagent access to other subagents","description":"","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-10T11:46:51.10983909+01:00","updated_at":"2025-12-10T12:28:12.239896299+01:00","closed_at":"2025-12-10T12:28:12.239896299+01:00"}
{"id":"codex-d55.1","title":"Update Subagent Configuration Schema","description":"Modify `SubagentMetadata` in `codex-rs/core/src/subagents.rs` to include an optional list of allowed subagent slugs (e.g., `allowed_subagents: Vec\u003cString\u003e`). This will allow subagents to declare which other subagents they need access to in their frontmatter.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T11:46:59.596535735+01:00","updated_at":"2025-12-10T12:10:37.503321809+01:00","closed_at":"2025-12-10T12:10:37.503321809+01:00","dependencies":[{"issue_id":"codex-d55.1","depends_on_id":"codex-d55","type":"parent-child","created_at":"2025-12-10T11:46:59.596858281+01:00","created_by":"daemon"}]}
{"id":"codex-d55.2","title":"Pass Subagent Context to ToolsConfig","description":"Update `SessionConfiguration` and `ToolsConfig` to carry the list of allowed subagents. In `codex-rs/core/src/tools/handlers/task.rs`, extract the `allowed_subagents` from metadata when spawning a subagent and pass it to the new session configuration. Root sessions should have full access (None), while subagents should default to no access (Some(vec![])) unless specified.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T11:47:06.411262442+01:00","updated_at":"2025-12-10T12:20:43.504662463+01:00","closed_at":"2025-12-10T12:20:43.504662463+01:00","dependencies":[{"issue_id":"codex-d55.2","depends_on_id":"codex-d55","type":"parent-child","created_at":"2025-12-10T11:47:06.411575129+01:00","created_by":"daemon"}]}
{"id":"codex-d55.3","title":"Conditionally Inject and Filter Task Tool","description":"Modify `build_specs` in `codex-rs/core/src/tools/spec.rs` to check `ToolsConfig.allowed_subagents`. If `None`, inject the task tool with full access. If `Some(list)`, only inject the task tool if the list is not empty, and filter the available agents in the tool description to match the allowed list. If the list is empty, do not inject the task tool.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T11:47:19.761597046+01:00","updated_at":"2025-12-10T12:23:18.651057619+01:00","closed_at":"2025-12-10T12:23:18.651057619+01:00","dependencies":[{"issue_id":"codex-d55.3","depends_on_id":"codex-d55","type":"parent-child","created_at":"2025-12-10T11:47:19.761959358+01:00","created_by":"daemon"}]}
{"id":"codex-d8a","title":"Gemini tokens ignored when API key present","description":"load_auth early returns CodexAuth::from_api_key_with_client when auth.json includes an API key, discarding gemini_accounts snapshot. Runtime then sees zero Gemini accounts and keeps using API key. Need to preserve auth snapshot so Gemini tokens remain accessible even when API key exists.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-06T13:09:00.722385922+01:00","updated_at":"2025-12-06T13:49:19.30910605+01:00","closed_at":"2025-12-06T13:49:19.30910605+01:00"}
{"id":"codex-i1t","title":"Implement Antigravity Provider Support","description":"","status":"in_progress","priority":1,"issue_type":"epic","created_at":"2025-12-06T12:34:26.379799781+01:00","updated_at":"2025-12-06T22:44:23.612368907+01:00"}
{"id":"codex-i1t.1","title":"Define Antigravity Protocol and Types","description":"Extend core types to recognize Antigravity as a distinct authentication mode and wire protocol.\n\n**Actions:**\n1.  **codex-rs/app-server-protocol/src/protocol/common.rs**:\n    *   Update `enum AuthMode` to include `Antigravity`.\n    *   This distinguishes the login/auth flow from standard Gemini.\n\n2.  **codex-rs/core/src/model_provider_info.rs**:\n    *   Update `enum WireApi` to include `Antigravity`.\n    *   Update `enum ProviderKind` to include `Antigravity` (optional, but recommended for consistency).\n\n**Why:**\nThis is the foundational type work needed before we can write the implementation logic.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-06T12:34:31.707276308+01:00","updated_at":"2025-12-06T22:46:13.199124796+01:00","closed_at":"2025-12-06T22:46:13.199124796+01:00","dependencies":[{"issue_id":"codex-i1t.1","depends_on_id":"codex-i1t","type":"parent-child","created_at":"2025-12-06T12:34:31.707575027+01:00","created_by":"daemon"}]}
{"id":"codex-i1t.2","title":"Add Antigravity Configuration and Constants","description":"Create the configuration module containing hardcoded credentials and endpoints.\n\n**Actions:**\n1.  **Create file**: `codex-rs/core/src/antigravity.rs`\n2.  **Add Constants** (Mirroring the Python reference implementation):\n    *   `ANTIGRAVITY_CLIENT_ID`: \"1071006060591-tmhssin2h21lcre235vtolojh4g403ep.apps.googleusercontent.com\"\n    *   `ANTIGRAVITY_CLIENT_SECRET`: \"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\"\n    *   `ANTIGRAVITY_AUTH_URL`, `ANTIGRAVITY_TOKEN_URL` (Standard Google OAuth endpoints).\n    *   `ANTIGRAVITY_ENDPOINT`: \"https://daily-cloudcode-pa.sandbox.googleapis.com\" (Note: Use the Sandbox URL as primary).\n    *   `ANTIGRAVITY_SCOPES`: Must include:\n        *   `https://www.googleapis.com/auth/cloud-platform`\n        *   `https://www.googleapis.com/auth/userinfo.email`\n        *   `https://www.googleapis.com/auth/cclog` (Critical)\n        *   `https://www.googleapis.com/auth/experimentsandconfigs` (Critical)\n\n**Why:**\nThese specific credentials and scopes are required to masquerade as the Antigravity client.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-06T12:34:38.497295683+01:00","updated_at":"2025-12-06T22:47:24.157608954+01:00","closed_at":"2025-12-06T22:47:24.157608954+01:00","dependencies":[{"issue_id":"codex-i1t.2","depends_on_id":"codex-i1t","type":"parent-child","created_at":"2025-12-06T12:34:38.4976193+01:00","created_by":"daemon"}]}
{"id":"codex-i1t.3","title":"Implement Antigravity Authentication Flow","description":"Implement the OAuth flow using the Antigravity credentials.\n\n**Actions:**\n1.  **codex-rs/core/src/auth.rs**:\n    *   Update `CodexAuth` to handle `AuthMode::Antigravity`.\n    *   In `refresh_token()` logic:\n        *   Check if `mode == AuthMode::Antigravity`.\n        *   If so, use `antigravity::ANTIGRAVITY_CLIENT_ID/SECRET` instead of the Gemini ones.\n    *   In `login()` (if applicable) or manual token setup paths, ensure the correct scopes are requested.\n2.  **codex-rs/core/src/token_data.rs**:\n    *   Reuse `GeminiTokenData` struct for storage, as the fields (access_token, refresh_token, project_id) are identical.\n\n**Why:**\nWe need to authenticate *as* Antigravity to be allowed to call the internal endpoints.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-06T12:34:44.751257296+01:00","updated_at":"2025-12-06T23:27:23.359225469+01:00","closed_at":"2025-12-06T23:27:23.359225469+01:00","dependencies":[{"issue_id":"codex-i1t.3","depends_on_id":"codex-i1t","type":"parent-child","created_at":"2025-12-06T12:34:44.751596443+01:00","created_by":"daemon"}]}
{"id":"codex-i1t.4","title":"Refactor Gemini Messages for Reusability","description":"Extract payload construction logic to allow wrapping.\n\n**Actions:**\n1.  **codex-rs/core/src/gemini_messages.rs**:\n    *   Locate the `stream_gemini_messages` function.\n    *   Extract the logic that builds the `GeminiRequest` struct (converting `Prompt`, `tools`, etc.) into a new public function:\n        ```rust\n        pub fn build_gemini_payload(prompt: \u0026Prompt, config: \u0026Config, ...) -\u003e Result\u003cGeminiRequest\u003e\n        ```\n    *   Make `GeminiRequest` and its inner types (`GeminiContent`, `GeminiTool`, etc.) public (or public to crate) so they can be used by the Antigravity module.\n\n**Why:**\nAntigravity uses the *exact same* internal payload structure, but wraps it in an outer envelope. We must not duplicate the complex logic of converting Codex prompts/tools into the Gemini format.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-06T12:34:50.699256599+01:00","updated_at":"2025-12-06T23:27:28.524168016+01:00","closed_at":"2025-12-06T23:27:28.524168016+01:00","dependencies":[{"issue_id":"codex-i1t.4","depends_on_id":"codex-i1t","type":"parent-child","created_at":"2025-12-06T12:34:50.69960826+01:00","created_by":"daemon"}]}
{"id":"codex-i1t.5","title":"Implement Antigravity Message Streaming","description":"Implement the core Antigravity request/response logic.\n\n**Actions:**\n1.  **Create file**: `codex-rs/core/src/antigravity_messages.rs`\n2.  **Request Logic**:\n    *   Call `gemini_messages::build_gemini_payload(...)` to get the inner model request.\n    *   Wrap it in the Antigravity envelope:\n        ```rust\n        #[derive(Serialize)]\n        struct AntigravityRequest {\n            project: String, // from token data\n            userAgent: String, // MUST be \"antigravity\"\n            requestId: String, // \"agent-{uuid}\"\n            model: String,     // e.g. \"gemini-3-pro-preview\"\n            request: GeminiRequest,\n        }\n        ```\n3.  **Streaming Logic**:\n    *   Send POST to `{ANTIGRAVITY_ENDPOINT}/v1internal:streamGenerateContent`.\n    *   Use `eventsource-stream` (or similar) to handle SSE.\n4.  **Response Unwrapping**:\n    *   The stream yields JSON chunks.\n    *   **Crucial Step**: The chunks are Antigravity envelopes. You must extract the inner `response` field.\n        *   Example Chunk: `{\"responseId\": \"...\", \"response\": { \"candidates\": [...] }}`\n        *   Extract the inner object and treat it exactly like a standard Gemini chunk.\n    *   Reuse `gemini_messages::handle_stream_chunk` (or similar logic) if possible, or adapt it to parse the unwrapped chunk.\n\n**Why:**\nThis is the core logic that differentiates Antigravity from standard Gemini. The envelope makes the server treat us as the internal \"CloudCode\" tool.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-06T12:34:57.840908107+01:00","updated_at":"2025-12-06T23:27:36.456056193+01:00","closed_at":"2025-12-06T23:27:36.456056193+01:00","dependencies":[{"issue_id":"codex-i1t.5","depends_on_id":"codex-i1t","type":"parent-child","created_at":"2025-12-06T12:34:57.841295316+01:00","created_by":"daemon"}]}
{"id":"codex-i1t.6","title":"Wire Antigravity into Client and Config","description":"Integrate the new provider into the main client dispatch.\n\n**Actions:**\n1.  **codex-rs/core/src/client.rs**:\n    *   In `ModelClient::stream()`, add a match arm for `WireApi::Antigravity`.\n    *   Call `antigravity_messages::stream_antigravity_messages(...)`.\n2.  **codex-rs/core/src/model_provider_info.rs**:\n    *   Ensure configuration loading (TOML) supports the new `wire_api = \"antigravity\"` string enum.\n\n**Why:**\nThis makes the new functionality accessible to the end user via their config.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-06T12:35:02.836823082+01:00","updated_at":"2025-12-06T23:53:10.512430351+01:00","closed_at":"2025-12-06T23:53:10.512430351+01:00","dependencies":[{"issue_id":"codex-i1t.6","depends_on_id":"codex-i1t","type":"parent-child","created_at":"2025-12-06T12:35:02.837109549+01:00","created_by":"daemon"}]}
{"id":"codex-p1z","title":"Improve tool output truncation policy","description":"Improve how codex-rs truncates tool outputs (shell commands, MCP tools, etc.) to better preserve useful context for the model.\n\n## Problem\nCurrent truncation uses a balanced 50/50 split (prefix + suffix), but:\n1. Stack traces, errors, and final results are usually at the END of output\n2. When output is truncated, the model has no way to retrieve the full output\n3. Non-OpenAI models (Claude, Gemini) can handle different truncation strategies\n\n## Current Behavior\n- **Prompt tells model**: \"Command line output will be truncated after 10 kilobytes or 256 lines\"\n- **Actual implementation**: Uses token-based (10k tokens) or byte-based (10KB) truncation, NOT line-based\n- OpenAI codex models: `TruncationPolicy::Tokens(10_000)`\n- Claude/Gemini: `TruncationPolicy::Bytes(10_000)`\n- Default fallback: `TruncationPolicy::Bytes(50_000)`\n\n## Research Findings\n- **gemini-cli**: Uses 20/80 head/tail split (1000 lines), 4MB threshold, writes full output to temp file\n- **opencode**: Uses 30k chars front-cut (loses tail)\n- **Claude Code**: Similar middle-cut but focuses on keeping errors visible\n\n## Goals\n1. Add configurable truncation bias (balanced vs tail-heavy) per model family\n2. Add file fallback mechanism so model can retrieve full output when needed\n3. Keep OpenAI models using balanced truncation (API requirement)\n4. Use tail-heavy truncation for Claude, Gemini, and other models","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-12T15:29:25.798282082+01:00","updated_at":"2025-12-12T16:19:23.491396911+01:00","closed_at":"2025-12-12T16:19:23.491396911+01:00"}
{"id":"codex-p1z.1","title":"Add TruncationBias enum to truncate.rs","description":"Add a new enum to control how truncation distributes budget between head and tail.\n\n## Implementation\n\nAdd to `core/src/truncate.rs`:\n\n```rust\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Default)]\npub enum TruncationBias {\n    #[default]\n    Balanced,    // 50/50 split - current behavior, required for OpenAI\n    TailHeavy,   // 20/80 split - better for error messages, stack traces\n}\n\nimpl TruncationBias {\n    pub fn head_ratio(\u0026self) -\u003e f64 {\n        match self {\n            TruncationBias::Balanced =\u003e 0.5,\n            TruncationBias::TailHeavy =\u003e 0.2,\n        }\n    }\n    \n    pub fn tail_ratio(\u0026self) -\u003e f64 {\n        1.0 - self.head_ratio()\n    }\n}\n```\n\n## Acceptance Criteria\n- [ ] Enum is public and exported from truncate module\n- [ ] Default is Balanced (backwards compatible)\n- [ ] Has helper methods for getting head/tail ratios\n- [ ] Unit tests for ratio calculations","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-12T15:29:47.607595444+01:00","updated_at":"2025-12-12T15:39:38.987192018+01:00","closed_at":"2025-12-12T15:39:38.987192018+01:00","dependencies":[{"issue_id":"codex-p1z.1","depends_on_id":"codex-p1z","type":"parent-child","created_at":"2025-12-12T15:29:47.60790742+01:00","created_by":"daemon"}]}
{"id":"codex-p1z.2","title":"Modify truncation functions to accept bias parameter","description":"Update the core truncation functions to use TruncationBias when splitting content.\n\n## Files to Modify\n- `core/src/truncate.rs`\n\n## Functions to Update\n\n### truncate_with_byte_estimate\nCurrently uses hardcoded 50/50 split. Change to:\n```rust\nfn truncate_with_byte_estimate(content: \u0026str, policy: TruncationPolicy, bias: TruncationBias) -\u003e String {\n    let budget = policy.byte_budget();\n    let head_budget = (budget as f64 * bias.head_ratio()) as usize;\n    let tail_budget = budget - head_budget;\n    // ... use head_budget and tail_budget for splitting\n}\n```\n\n### truncate_with_token_budget  \nSame pattern - accept bias parameter and use ratios.\n\n### truncate_text / formatted_truncate_text\nAdd bias parameter, pass through to underlying functions.\n\n## Backwards Compatibility\n- All existing call sites will need updating\n- Default bias should be Balanced to maintain current behavior\n\n## Acceptance Criteria\n- [ ] All truncation functions accept TruncationBias parameter\n- [ ] Balanced bias produces identical output to current behavior\n- [ ] TailHeavy bias keeps 80% of budget for tail content\n- [ ] Unit tests verify both bias modes\n- [ ] UTF-8 boundary handling still works correctly","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-12T15:29:58.099070837+01:00","updated_at":"2025-12-12T15:44:25.948678587+01:00","closed_at":"2025-12-12T15:44:25.948678587+01:00","dependencies":[{"issue_id":"codex-p1z.2","depends_on_id":"codex-p1z","type":"parent-child","created_at":"2025-12-12T15:29:58.099439081+01:00","created_by":"daemon"},{"issue_id":"codex-p1z.2","depends_on_id":"codex-p1z.1","type":"blocks","created_at":"2025-12-12T15:31:45.169751674+01:00","created_by":"daemon"}]}
{"id":"codex-p1z.3","title":"Add truncation_bias field to ModelFamily","description":"Add truncation_bias field to ModelFamily struct and set appropriate values per model.\n\n## Files to Modify\n- `core/src/openai_models/model_family.rs`\n\n## Changes\n\n### Add field to ModelFamily struct\n```rust\npub struct ModelFamily {\n    // ... existing fields ...\n    pub truncation_policy: TruncationPolicy,\n    pub truncation_bias: TruncationBias,  // NEW\n    pub mcp_truncation_policy: TruncationPolicy,\n    pub mcp_truncation_bias: TruncationBias,  // NEW (may differ for MCP)\n}\n```\n\n### Set per-model values\n\n| Model Family | Bias | Rationale |\n|-------------|------|-----------|\n| gpt-* (OpenAI) | Balanced | API requires balanced truncation |\n| claude-* | TailHeavy | Anthropic handles varied formats well |\n| gemini-* | TailHeavy | Google models handle tail-heavy well |\n| o1-*, o3-* | Balanced | OpenAI reasoning models |\n| Default/Unknown | Balanced | Safe fallback |\n\n### Update model_family! macro\nAdd truncation_bias to the macro with default Balanced.\n\n## Acceptance Criteria\n- [ ] ModelFamily has truncation_bias field\n- [ ] All OpenAI models use Balanced\n- [ ] Claude and Gemini models use TailHeavy\n- [ ] Default fallback is Balanced\n- [ ] model_family! macro supports the new field","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-12T15:30:13.310242031+01:00","updated_at":"2025-12-12T15:45:56.903728718+01:00","closed_at":"2025-12-12T15:45:56.903728718+01:00","dependencies":[{"issue_id":"codex-p1z.3","depends_on_id":"codex-p1z","type":"parent-child","created_at":"2025-12-12T15:30:13.310579144+01:00","created_by":"daemon"},{"issue_id":"codex-p1z.3","depends_on_id":"codex-p1z.1","type":"blocks","created_at":"2025-12-12T15:31:45.137942484+01:00","created_by":"daemon"}]}
{"id":"codex-p1z.4","title":"Wire truncation_bias through TurnContext to truncation call sites","description":"Pass truncation_bias from ModelFamily through TurnContext to all places where truncation is performed.\n\n## Context Flow\nModelFamily -\u003e TurnContext -\u003e truncation functions\n\n## Files to Modify\n\n### core/src/codex.rs or turn context\nAdd truncation_bias to TurnContext (it already has truncation_policy).\n\n### core/src/tools/mod.rs\nUpdate format_exec_output_* functions to accept and use bias:\n- format_exec_output_for_model_structured\n- format_exec_output_for_model_freeform  \n- format_exec_output_str\n\n### core/src/mcp_tool_call.rs\nUpdate MCP truncation to use mcp_truncation_bias.\n\n### core/src/unified_exec/session.rs and session_manager.rs\nUpdate unified exec truncation to use bias.\n\n### core/src/context_manager/history.rs\nIf truncation happens here, wire through bias.\n\n## Acceptance Criteria\n- [ ] TurnContext carries truncation_bias from ModelFamily\n- [ ] All truncation call sites use the bias from context\n- [ ] No hardcoded bias values in truncation calls\n- [ ] Tests pass with both Balanced and TailHeavy configurations","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-12T15:30:26.014245293+01:00","updated_at":"2025-12-12T15:52:10.449645201+01:00","closed_at":"2025-12-12T15:52:10.449645201+01:00","dependencies":[{"issue_id":"codex-p1z.4","depends_on_id":"codex-p1z","type":"parent-child","created_at":"2025-12-12T15:30:26.014684662+01:00","created_by":"daemon"},{"issue_id":"codex-p1z.4","depends_on_id":"codex-p1z.3","type":"blocks","created_at":"2025-12-12T15:31:45.127437635+01:00","created_by":"daemon"},{"issue_id":"codex-p1z.4","depends_on_id":"codex-p1z.2","type":"blocks","created_at":"2025-12-12T15:31:45.14868704+01:00","created_by":"daemon"}]}
{"id":"codex-p1z.5","title":"Add file fallback for truncated output","description":"When output is truncated, save full content to a temp file and tell the model how to retrieve it.\n\n## Motivation\nCurrently when output is truncated, the model has no way to see the full content. Gemini-cli solves this by:\n1. Writing full output to a temp file\n2. Including the file path in the truncated message\n3. Instructing model to use read_file with offset/limit to paginate\n\n## Implementation\n\n### Add to truncate.rs\n```rust\npub struct TruncationResult {\n    pub content: String,\n    pub saved_file: Option\u003cPathBuf\u003e,\n    pub original_size: usize,\n}\n\npub fn truncate_with_file_fallback(\n    content: \u0026str,\n    policy: TruncationPolicy,\n    bias: TruncationBias,\n    temp_dir: \u0026Path,\n    call_id: \u0026str,\n) -\u003e std::io::Result\u003cTruncationResult\u003e\n```\n\n### Message format when truncated\n```\nOutput was truncated ({original_size} bytes -\u003e {truncated_size} bytes).\nFull output saved to: /tmp/codex/{call_id}.output\n\nTo read full output, use read_file tool with:\n- offset=0, limit=100 for first 100 lines\n- offset=N to skip N lines\n- limit=M to read M lines at a time\n\nTruncated output:\n{head}\n... [CONTENT TRUNCATED] ...\n{tail}\n```\n\n### Config\nAdd to Config:\n- `truncation_save_to_file: bool` (default: true)\n- Use existing `codex_home` for temp directory\n\n## Acceptance Criteria\n- [ ] Full output is saved to temp file when truncated\n- [ ] Truncated message includes file path and usage instructions\n- [ ] File is written atomically (write to .tmp then rename)\n- [ ] Graceful fallback if file write fails\n- [ ] Temp files are cleaned up on session end (optional, can be separate task)\n- [ ] Works with both Balanced and TailHeavy bias","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-12T15:30:40.915571164+01:00","updated_at":"2025-12-12T16:19:13.15430907+01:00","closed_at":"2025-12-12T16:19:13.15430907+01:00","dependencies":[{"issue_id":"codex-p1z.5","depends_on_id":"codex-p1z","type":"parent-child","created_at":"2025-12-12T15:30:40.915945779+01:00","created_by":"daemon"},{"issue_id":"codex-p1z.5","depends_on_id":"codex-p1z.4","type":"blocks","created_at":"2025-12-12T15:31:45.180079073+01:00","created_by":"daemon"}]}
{"id":"codex-p1z.6","title":"Add offset/limit parameters to read_file tool","description":"Extend the read_file tool to support offset and limit parameters for paginated reading.\n\n## Motivation\nWhen output is truncated and saved to a file, the model needs a way to read specific portions without loading the entire file. Gemini-cli's read_file tool supports:\n- `offset`: Skip N lines from the beginning\n- `limit`: Read only M lines\n\n## Current State\nCheck if read_file already supports these parameters. If not, add them.\n\n## Implementation\n\n### Update tool schema\n```json\n{\n  \"name\": \"read_file\",\n  \"parameters\": {\n    \"path\": { \"type\": \"string\" },\n    \"offset\": { \"type\": \"integer\", \"description\": \"Number of lines to skip from start\" },\n    \"limit\": { \"type\": \"integer\", \"description\": \"Maximum number of lines to read\" }\n  }\n}\n```\n\n### Update handler\n```rust\n// In tools/handlers/read_file.rs\nfn read_file_with_range(path: \u0026Path, offset: Option\u003cusize\u003e, limit: Option\u003cusize\u003e) -\u003e Result\u003cString\u003e\n```\n\n### Behavior\n- `offset=None, limit=None`: Read entire file (current behavior)\n- `offset=100, limit=None`: Skip first 100 lines, read rest\n- `offset=None, limit=50`: Read first 50 lines\n- `offset=100, limit=50`: Skip 100 lines, read next 50\n\n## Acceptance Criteria\n- [ ] read_file accepts offset and limit parameters\n- [ ] Parameters are optional with sensible defaults\n- [ ] Line counting is 0-based\n- [ ] Works correctly with UTF-8 content\n- [ ] Returns helpful message if offset exceeds file length\n- [ ] Tool description explains the parameters","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-12T15:30:53.775036219+01:00","updated_at":"2025-12-12T16:19:17.070377645+01:00","closed_at":"2025-12-12T16:19:17.070377645+01:00","dependencies":[{"issue_id":"codex-p1z.6","depends_on_id":"codex-p1z","type":"parent-child","created_at":"2025-12-12T15:30:53.775426194+01:00","created_by":"daemon"},{"issue_id":"codex-p1z.6","depends_on_id":"codex-p1z.5","type":"blocks","created_at":"2025-12-12T15:31:45.158761668+01:00","created_by":"daemon"}]}
{"id":"codex-p1z.7","title":"Add tests for truncation bias modes","description":"Comprehensive tests for the new truncation bias functionality.\n\n## Test Cases\n\n### Unit tests in truncate.rs\n\n1. **Balanced bias produces 50/50 split**\n   - Input: 1000 char string, budget 200\n   - Expected: ~100 chars head + marker + ~100 chars tail\n\n2. **TailHeavy bias produces 20/80 split**  \n   - Input: 1000 char string, budget 200\n   - Expected: ~40 chars head + marker + ~160 chars tail\n\n3. **UTF-8 boundary handling with both biases**\n   - Input: String with multi-byte chars (emojis)\n   - Expected: No broken UTF-8 sequences\n\n4. **Token-based truncation respects bias**\n   - Similar tests but with token policy\n\n5. **Edge cases**\n   - Empty string\n   - String shorter than budget\n   - Very small budget (e.g., 10 bytes)\n\n### Integration tests\n\n1. **Model family uses correct bias**\n   - Claude model -\u003e TailHeavy\n   - GPT model -\u003e Balanced\n\n2. **TurnContext propagates bias correctly**\n\n## Files\n- `core/src/truncate.rs` (unit tests module)\n- `core/tests/` (integration tests if needed)\n\n## Acceptance Criteria\n- [ ] All bias modes have dedicated test coverage\n- [ ] Edge cases are tested\n- [ ] Tests use pretty_assertions::assert_eq\n- [ ] Snapshot tests for truncation output format (if applicable)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-12T15:31:06.179192426+01:00","updated_at":"2025-12-12T15:53:25.964832188+01:00","closed_at":"2025-12-12T15:53:25.964832188+01:00","dependencies":[{"issue_id":"codex-p1z.7","depends_on_id":"codex-p1z","type":"parent-child","created_at":"2025-12-12T15:31:06.179526775+01:00","created_by":"daemon"},{"issue_id":"codex-p1z.7","depends_on_id":"codex-p1z.4","type":"blocks","created_at":"2025-12-12T15:31:45.116722775+01:00","created_by":"daemon"}]}
{"id":"codex-u12","title":"Use model_context_window from config for context percentage calculation","description":"","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-12-07T16:13:59.274785935+01:00","updated_at":"2025-12-07T16:18:05.979811379+01:00","closed_at":"2025-12-07T16:18:05.979811379+01:00"}
{"id":"codex-vq1","title":"ChatGPT login overwrites Gemini tokens","description":"persist_tokens_async in login/server.rs builds a fresh AuthDotJson with empty gemini_accounts when saving ChatGPT tokens, wiping existing Gemini credentials. Need to merge with existing auth.json so Gemini accounts survive ChatGPT login.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-06T13:55:23.755383003+01:00","updated_at":"2025-12-06T13:57:34.877510865+01:00","closed_at":"2025-12-06T13:57:34.877510865+01:00"}
